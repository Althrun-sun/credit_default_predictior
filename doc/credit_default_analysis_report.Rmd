---
title: "Credit Default Analysis Report"
author: "Arjun Radhakrishnan, Morris Zhao, Althrun Sun, Ken Wang"
date: "2022-11-25"
output:
  github_document:
    toc: true
bibliography: default_credit_references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(reticulate)
```

```{python code block, include=FALSE}

```

## Introduction

For the project, we are trying to answer the question that given a credit card customer's payment history and demographic information like gender, age, and education level, would the customer default on the next bill payment? A borrower is said to be in default when they are unable to make their interest or principal payments on time, miss installments, or cease making them altogether. The answer to this query is crucial since it allows financial organizations to assess a customer's creditworthiness and set suitable credit limit ranges using an efficient predictive model. It also helps them take preemptive actions to secure their assets. Due to the class imbalance, we must evaluate the model's effectiveness using different metrics, such as precision, recall, or F1 score. Our model's primary focus is the class "default payment," which refers to payment defaults made by clients. As a result, we are treating `default` as the positive class, and `not defaulting` as the negative class. In this case, it is important for financial institutions to identify potential clients that may make a default payment. 

Our objective is to predict as many default payments as we can with accuracy. In other words, we are maximizing the number of true positives while reducing false positives as much as possible. Thus, they can prevent asset loss in advance. Additionally, Type II errors are also important since it will be costly for the institutions to assume people, who can make the payment, would default as it would affect the organization's reputation. Therefore, we need to balance both Types of errors and the best way would be to score the model on the F1 score as it is the harmonic mean of recall which shows many among all positive examples are correctly identified and precision which shows how many among the positive examples are truly positive.

In this report, we attempt to use machine-learning algorithms to predict whether a client would default a payment or not, given a set of the client's information. 

## Methods

This project is based on Python[@python] and including the following python packages:pandas[@pandas],scikit-learn[@scikit-learn],altair[@altair],matplotlib[@matplotlib],numpy[@numpy],uci_ml_data_set[@uci_ml_data_set]

### Data

The data set used in the project was produced by Yeh, I. C., and Lien, C. H., and it is freely accessible for download at the UCI Machine Learning Repository [@uci_ml_data_set] (with the title "default of credit card clients" in 2016). The [dataset](<https://github.com/UBC-MDS/credit_default_prediction_group_20/tree/main/data/raw>) is based on examples of Taiwanese credit card clients defaulting from April to September. Each observation in the 30000-observation dataset reflects the data of a certain client. The dataset has no missing values and has 24 features which are gender, age, marital status, ID, Repayment Status, and Bill and Pay amounts. The final target indicates whether the client will default or not. The 24 features can be groups as categorical, numeric, and binary.

Some of the key pre-processings performed in the data includes:
- As ID is the ID of each client, which is unique, feature is dropped. 
- Despite being categorical in nature, SEX will be regarded as a binary value. 
- As there are unknown values in the `EDUCATION` feature, they were combined and grouped along with "Others". Finally, the categories were encoded as 1 for high school, 2 for university, 3 for graduate school, and 4 for others. 
- As there are unknown values in the `MARRIAGE` feature, they were combined and grouped along with "Others". Finally, the categories were encoded as 1 for married, 2 for single, 3 for others.

As shown in the figure 1. pie chart for target, the target (default payment next month) is an imbalanced feature. There are more cases of not defaulting than defaulting. 

Figure 1. pie chart for target
![](../results//eda/images/target_proportion.jpg)


The BILL AMT features, the features that reflect the bill amount for each month during the six months from April to September 2005, where BILL AMT1 indicates the bill amount for April, show strong positive correlations. From this, we can infer that larger monthly bill amounts would probably result in higher monthly bill amounts the following month. Also, this could be due to the accumulation of debt as a result of late payments. Although BILL AMT features have a high correlation amongst themselves, most features have poor linear correlation against the target since Pearson Correlation Coefficient against the target for most features is low. 


Figure 2. Correlation graph
![](../results//eda/images/corr_plot.png)


### Analysis




## Improvement and limitation
Understanding the limitations and assumptions made during the prediction process plays a crucial role in understanding the validity and reliability of the results. One of the critical limitations that blocks us from extrapolating the results to the present day is that the data is old (taken in 2005), and there have been significant change in human nature and patterns since 2005. There are limitations also introduced due to the presence of data that was absent in the metadata for the features EDUCATION and MARRIAGE. These features contain unknown levels which are not described in the documentation. With number of defaulters at approximately at 25%, the number of defaulters is relatively large compared to what we would expect in real life. This could be due an efffect of Taiwanese economy this time period or could be due to improper data collection. To improve the analysis, we could perform feature enginneering based on expert domain knowledge that could boost the model performance. Although we have analyzed the performance of RFC, KNN, SVC, and LR, we could try analyzing the performance GradientBoostingClassifier. We could have also tried using SMOTE or a different method of handling class imbalance. To generalize the analysis to the current years, the first step would be to take more recent data that includes more features such as asset to debt ratio, occupation, income, and household size. It would also be better to get the data across varias other countries to better train our model on the trends in credit default payments. 


## References
